{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to My Digital Garden","text":"<p>This is a space where I share my learnings, thoughts, and experiments. You'll find a collection of my personal notes and things I am learning.</p>"},{"location":"#gemini-cookbook","title":"Gemini Cookbook","text":"<p>I'm excited to introduce my \"Cookbook\" series! This is where I'll be sharing step-by-step guides and practical examples for various technologies.</p> <p>The first cookbook in the series is the Google Cloud Gemini Cookbook.</p>"},{"location":"#blog","title":"Blog","text":"<p>I also have a blog where I post short articles and updates. It's a place for more informal thoughts and quick tips.</p> <p>I hope you find these resources helpful!</p>"},{"location":"Gemini/","title":"Getting Started: Gemini Cookbook Setup","text":"<p>This guide provides step-by-step instructions to set up your local environment and Google Cloud project to follow the recipes in the Gemini Cookbook.</p>"},{"location":"Gemini/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following:</p> <ul> <li>Python: Version 3.8 or higher.</li> <li>Google Cloud Account: An active GCP account with billing enabled. If   you're new, you can sign up for a   free trial.</li> <li>Basic Knowledge: Familiarity with Python, the command line, and Git.</li> </ul>"},{"location":"Gemini/#1-environment-setup","title":"1. Environment Setup","text":"<p>First, let's set up the project on your local machine.</p>"},{"location":"Gemini/#clone-the-repository","title":"Clone the Repository","text":"<p>Open your terminal and clone the cookbook's GitHub repository:</p> <pre><code>git clone https://github.com/msampathkumar/msampathkumar.github.io.git\ncd msampathkumar.github.io\n</code></pre>"},{"location":"Gemini/#set-up-a-virtual-environment","title":"Set Up a Virtual Environment","text":"<p>It's a best practice to use a virtual environment to manage project dependencies.</p> <pre><code># Create a virtual environment\npython3 -m venv .venv\n\n# Activate the virtual environment\n# On macOS and Linux:\nsource .venv/bin/activate\n# On Windows:\n# .\\.venv\\Scripts\\activate\n</code></pre>"},{"location":"Gemini/#install-dependencies","title":"Install Dependencies","text":"<p>Install the common Python packages needed for the cookbook examples:</p> <pre><code>pip install google-generativeai google-cloud-aiplatform streamlit python-dotenv\n</code></pre>"},{"location":"Gemini/#2-google-cloud-configuration-cli","title":"2. Google Cloud Configuration (CLI)","text":"<p>Next, configure the Google Cloud CLI (<code>gcloud</code>) to interact with your GCP project.</p>"},{"location":"Gemini/#install-and-initialize-google-cloud-sdk","title":"Install and Initialize Google Cloud SDK","text":"<p>If you don't have it, install the Google Cloud SDK. After installation, initialize it:</p> <pre><code>gcloud init\n</code></pre> <p>Follow the on-screen prompts to log in, select your GCP project, and set a default region.</p>"},{"location":"Gemini/#authenticate-for-local-development","title":"Authenticate for Local Development","text":"<p>For local development, authenticating with your user credentials is the easiest way to get started.</p> <pre><code>gcloud auth application-default login\n</code></pre>"},{"location":"Gemini/#enable-required-apis","title":"Enable Required APIs","text":"<p>You need to enable the Vertex AI API to use Gemini models.</p> <pre><code># Set your project ID (if you didn't during gcloud init)\nexport PROJECT_ID=\"your-gcp-project-id\"\ngcloud config set project $PROJECT_ID\n\n# Enable the Vertex AI API\ngcloud services enable aiplatform.googleapis.com --project $PROJECT_ID\n</code></pre> <p>Note: Replace <code>your-gcp-project-id</code> with your actual Google Cloud Project ID.</p>"},{"location":"Gemini/#next-steps","title":"Next Steps","text":"<p>You are all set! Your environment is configured and you're ready to start building with Gemini.</p> <p>Head over to the Full Lesson Plan to see all the available recipes.</p>"},{"location":"HelloWorld/","title":"Hello World","text":"<p>this is an example!</p>"},{"location":"cookbook/","title":"Google Cloud Gemini Cookbook: A Practical Guide to Learn Fundamentals and Build Applications","text":""},{"location":"cookbook/#vision-executive-summary","title":"Vision &amp; Executive Summary","text":"<p>This project is a cookbook-style series designed to teach developers and AI enthusiasts how to build practical, real-world applications using Google Cloud's Gemini models. Through a series of hands-on blog posts and a central GitHub repository, this guide will provide clear, step-by-step instructions, making generative AI accessible even to those with limited prior experience. The goal is to empower builders, foster a collaborative community, and showcase the power of Gemini.</p>"},{"location":"cookbook/#guiding-principles","title":"Guiding Principles","text":"<ul> <li>Practical First: Focus on hands-on examples and code snippets that solve   real problems.</li> <li>Clarity and Simplicity: Provide clear, step-by-step instructions that are   easy to follow.</li> <li>Gemini Focused: Deep-dive into Google Cloud Gemini, its specific   features, and its ecosystem.</li> <li>Fundamental Concepts: Cover the necessary foundational knowledge to use   Gemini effectively.</li> </ul>"},{"location":"cookbook/#target-audience","title":"Target Audience","text":"<p>This series is for developers, AI enthusiasts, and anyone interested in learning how to build practical AI applications with Gemini.</p>"},{"location":"cookbook/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic Python programming knowledge.</li> <li>A Google Cloud Platform (GCP) account with billing enabled.</li> <li>Familiarity with the command line and GitHub is helpful.</li> </ul>"},{"location":"cookbook/#content-outline-lesson-plan","title":"Content Outline &amp; Lesson Plan","text":"<p>The series will be released as a sequence of lessons, each building upon the last.</p> <ul> <li> <p>Lesson 1: Building a Basic Chatbot with Gemini and Streamlit</p> </li> <li> <p>Objective: Introduce the fundamentals of the Gemini API and build a     simple, interactive chatbot and deploy to Cloud.</p> </li> <li>Core Concepts: API keys, model initialization, generating text,     streaming responses.</li> <li> <p>Tech Stack: Python, <code>google-genai</code> SDK, Streamlit.</p> </li> <li> <p>Lesson 2: Enhancing the Chatbot with Memory and Gemma</p> </li> <li> <p>Objective: Add conversational memory to the chatbot and explore using     open models like Gemma for specific tasks.</p> </li> <li>Core Concepts: Chat history management, context passing, integrating     local/open-source models.</li> <li>Tech Stack: Vertex AI Memory Bank, Gemma, (Optional) Google ADK.</li> </ul>"},{"location":"cookbook/#future-lessons-proposed-agenda","title":"Future Lessons (Proposed Agenda)","text":"<ul> <li> <p>Lesson 3: Unlocking Multimodality with Gemini Pro Vision</p> </li> <li> <p>Objective: Build an application that can understand and analyze     information from both images and text simultaneously.</p> </li> <li>Use Case Example: An app that takes a picture of a whiteboard diagram     and generates code, or identifies products in an image and searches for     them online.</li> <li> <p>Core Concepts: Multimodal prompts, image data handling, combining     visual and text inputs, prompt engineering for vision models.</p> </li> <li> <p>Lesson 4: Building a Knowledge Base Q&amp;A with RAG</p> </li> <li> <p>Objective: Create a Retrieval-Augmented Generation (RAG) system that     answers questions based on a custom document set (e.g., PDFs, text files).</p> </li> <li>Use Case Example: A chatbot that can answer questions about a company\u2019s     internal policy documents.</li> <li> <p>Core Concepts: Vector embeddings, vector databases (e.g., ChromaDB,     Pinecone), document chunking, semantic search.</p> </li> <li> <p>Lesson 5: Advanced RAG with Knowledge Graphs</p> </li> <li> <p>Objective: Go beyond simple vector search by building a RAG system that     understands the relationships between entities in your data, leading to     more accurate and context-aware answers.</p> </li> <li>Use Case Example: A financial analyst bot that can answer complex     queries like \"Which companies in our portfolio have board members who also     sit on the boards of their competitors?\"</li> <li> <p>Core Concepts: Entity and relationship extraction, building a knowledge     graph (e.g., with Neo4j), translating natural language to graph queries     (e.g., Cypher), combining graph retrieval with LLM generation.</p> </li> <li> <p>Lesson 6: Creating Autonomous Agents with Function Calling</p> </li> <li> <p>Objective: Empower Gemini to interact with external tools and APIs to     perform actions in the real world.</p> </li> <li>Use Case Example: A personal assistant that can check the weather, send     an email, or book a meeting by calling external APIs.</li> <li> <p>Core Concepts: Tool definition, function calling, structured data     extraction, handling API errors and responses.</p> </li> <li> <p>Lesson 7: Building Collaborative AI with Multi-Agent Systems</p> </li> <li> <p>Objective: Design a system where multiple specialized AI agents     collaborate to solve a complex problem that a single agent could not handle     alone.</p> </li> <li>Use Case Example: A research team with a \"Web Search\" agent, a \"Data     Analyst\" agent, and a \"Report Writer\" agent that work together to produce a     market analysis.</li> <li> <p>Core Concepts: Agent roles and specialization, inter-agent     communication, task decomposition, state management, and using a     manager/orchestrator agent.</p> </li> <li> <p>Lesson 8: Practical AI Safety and Model Evaluation</p> </li> <li> <p>Objective: Learn to build responsible, reliable AI applications and     objectively measure their performance before they reach production.</p> </li> <li>Use Case Example: Adding a validation step to a customer service bot to     ensure its answers are factually correct and non-toxic before sending them     to a user.</li> <li> <p>Core Concepts: Implementing guardrails, protecting against prompt     injection, detecting and mitigating bias, using evaluation frameworks     (e.g., RAGAs, TruLens) to measure faithfulness and relevance.</p> </li> <li> <p>Lesson 9: Deploying and Scaling on Google Cloud</p> </li> <li> <p>Objective: Take a prototype application and prepare it for production.</p> </li> <li>Core Concepts: Containerizing with Docker, deploying to Cloud Run,     managing API keys securely with Secret Manager, monitoring and logging.</li> </ul>"},{"location":"cookbook/#distribution-community-strategy","title":"Distribution &amp; Community Strategy","text":"<ul> <li>Source of Truth: A public GitHub repository will host all code,   resources, and drafts.</li> <li>Primary Publications: Blog posts will be published on Medium.com and   Dev.to to reach a broad developer audience.</li> <li>Community Engagement: Announcements, key takeaways, and discussions will   be shared on X (formerly Twitter) and LinkedIn to foster community   interaction and feedback.</li> </ul>"},{"location":"cookbook/#potential-impact-success-metrics","title":"Potential Impact &amp; Success Metrics","text":"<ul> <li>Empower Developers: Lower the barrier to entry for building and deploying   AI-powered applications.</li> <li>Foster Community: Create a hub for Gemini users to share knowledge,   collaborate, and get feedback.</li> <li>Showcase Gemini: Highlight the versatility and power of Gemini for   solving real-world problems.</li> <li>Success Metrics: Track GitHub stars/forks, blog post views/claps, social   media engagement, and community contributions.</li> </ul>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/ProjectMgmt/RACI/","title":"RACI Matrix","text":"<p>A RACI chart can be an extremely effective way to define project roles, give direction to each team member and stakeholder, and ensure work gets done efficiently. Having a RACI chart available throughout the duration of your project as a quick visual can be invaluable. In this reading, we will cover the function of a RACI chart and its components and explore how project managers use RACI charts to define and document project roles and responsibilities.</p> <p>Elements of a RACI chart A RACI chart creates clear roles and gives direction to each team member and stakeholder. Over your career, you may hear a RACI chart referred to as a Responsibility Assignment Matrix (RAM), RACI diagram, or RACI matrix. The ultimate goal of this chart is to clarify each person\u2019s role on your project.</p> <p>First, let\u2019s break down each of the roles people can be assigned:</p> <p>R: Responsible: who gets the work done</p> <p>A: Accountable: who makes sure the work is done</p> <p>C: Consulted: who gives input or feedback on work</p> <p>I: Informed: who needs to know the outcome</p> <p>Note that RACI charts can be organized in different ways, depending on personal preference, number of tasks being assigned, and number of people involved. In the previous video, we showed you one RACI chart format. The template below shows another way a typical RACI chart might be organized:</p> <p></p> <p>Responsible Individuals who are assigned the \u201cresponsible\u201d role for a task are the ones who are actually doing the work to complete the task. Every task needs at least one responsible party. It\u2019s a best practice to try to limit the number of team members assigned to a task\u2019s responsible role, but in some cases, you may have more than one.</p> <p>A couple of questions to ask yourself when determining which person or people should be placed in the responsible role for a given task are:</p> <p>What department does the work fall under?</p> <p>Who will perform the work?</p> <p>It is helpful to evaluate the people on your team to determine the role that suits them. Remember that you may need to list roles rather than names, if some people take on more than one role.</p> <p>Let\u2019s dig deeper into our example with Office Green. Our task is to develop price points for the project, and the Financial Analyst will complete the work for this task. Therefore, we will list \u201cFinancial Analyst\u201d in the responsible role for this task in the RACI chart.</p> <p>A section of a RACI chart, where the Financial Analyst is in the \"responsible\" role Accountable The \u201caccountable\u201d person is responsible for making sure the task gets done. It is important to have only one individual accountable for each task. This helps clarify ownership of the task. The accountable person ultimately has the authority to approve the deliverable of the responsible party.</p> <p>In order to determine who should be tagged as the accountable team member, consider:</p> <p>Who will delegate the task to be completed?</p> <p>Who will review the work to determine if the task is complete?</p> <p>You may encounter a situation where the responsible party is also accountable, but where possible, it is helpful to separate these roles. Ensuring that accountability is not shared ensures that there is no confusion on who the ownership belongs to.</p> <p>Continuing with our Office Green example, you have assigned the \u201caccountable\u201d role to the Head of Finance. The Head of Finance has to make sure the project stays in budget and makes a profit, so they have the ultimate authority over the price points for the product. Therefore, they will need to approve the Financial Analyst\u2019s work on the task.</p> <p>A section of a RACI chart, where the Head of Finance is in the \"accountable\" role Consulted Team members or stakeholders who are placed in the \u201cconsulted\u201d role have useful information to help complete the task. There is no maximum or minimum number of people who can be assigned a \u201cconsulted\u201d role, but it\u2019s important that each person has a reason for being there.</p> <p>Here are a few ways you can help identify who is appropriate for the role:</p> <p>Who will the task impact?</p> <p>Who will have input or feedback for the responsible person to help the work be completed?</p> <p>Who are the subject matter experts (SMEs) for the task?</p> <p>The consulted people will be in frequent, two-way communication with the responsible party, so it is key to make sure that the right people are in this role to help accomplish the task efficiently and correctly.</p> <p>Back to the project at Office Green, we\u2019ve got a \u201cresponsible\u201d Financial Analyst and an \u201caccountable\u201d Head of Finance. Who else would need to provide input on the product\u2019s price points? Whose decisions and feedback will directly affect the task? The Director of Product will need to be consulted on the matter, as they oversee all product offerings. This person will have information about potential changes to the product and how these changes might affect price points.</p> <p>A section of a RACI chart, where the Director of Product is in the \"consulted\" role Informed Individuals who are identified as needing to be \u201cinformed\u201d need to know the final decisions that were made and when a task is completed. It is common to have many people assigned to this category and for some team members to be informed on most tasks. Team members or stakeholders here will not be asked for feedback, so it is key to make sure people who are in this group only require status updates and do not need to provide any direct feedback for the completion of the effort.</p> <p>Key questions to ask yourself in order to ensure that you have appropriately captured individuals in the \u201cinformed\u201d role are:</p> <p>Who cares about this task\u2019s completion?</p> <p>Who will be affected by the outcome?</p> <p>Now that you\u2019ve determined who is responsible, accountable, and consulted on the Office Green project task, it is time to determine who needs to be informed about the task. Your Financial Analyst has set the price points with input from the Director of Product, and the Head of Finance has approved. You will now need to inform the Sales Team about the final price points, as they will need this information to sell the product.</p> <p>A section of a RACI chart, where the Sales Team is in the \"informed\" role Pro tip: You could end up with a large number of team members and stakeholders who are placed in the \u201cinformed\u201d role. If so, make sure that you have a plan to keep them informed that is not labor-intensive. Something as easy as view-only access to your project plan or meeting notes could prevent you from having to create separate communications along the way.</p> <p>Key takeaway The RACI chart is a valuable tool. It can help you define and document project roles and responsibilities, give direction to each team member and stakeholder, and ensure work gets done efficiently. A RACI chart can also help you analyze and balance the workload of your team. While it may take many revisions to make sure that your team members and stakeholders are being placed into the right roles in your RACI chart, doing this work up front helps save time and prevent miscommunications later on.</p>"},{"location":"blog/ProjectMgmt/Tasks-and-Milestones/","title":"Tasks &amp; Milestones","text":"<p>A project task is an activity that needs to be accomplished within a set period of time and is assigned to one or more individuals for completion. The work of a project is broken down into many different project tasks.</p> <p>Tip1: When creating a task, start with a verb. Example: \u201cDevelop a proposal.\u201d, \"Create \", Tip2: Provide as much as possible when creating tasks.</p> <p>A project milestone is an important point within the project schedule that usually signifies the completion of a major deliverable. Milestones are significant checkpoints in your project, and keeping track of them helps ensure that your project is on schedule to meet its goals.</p> <p></p> <p>Setting tasks can help you clearly define milestones. You can do this in two ways:</p> <p>Top-down scheduling: In this approach, the project manager lays out the higher-level milestones, then works to break down the effort into project tasks. The project manager works with their team to ensure that all tasks are captured.</p> <p>Bottom-up scheduling: In this approach, the project manager looks at all of the individual tasks that need to be completed and then rolls those tasks into manageable chunks that lead to a milestone.</p>"},{"location":"blog/ProjectMgmt/Tasks-and-Milestones/#work-breakdown-structure-wbs-tool","title":"Work breakdown Structure (WBS) (Tool)","text":"<p>A work breakdown structure is tool to help us organize our work in a way that makes sense for our team. It\u2019s like a map of the project, showing what we\u2019re going to do and how it will be done.</p> <p>Once way to do this is by build a GRAPH.</p>"},{"location":"blog/ProjectMgmt/Tasks-and-Milestones/#workload-balance-strategy","title":"Workload Balance Strategy","text":"<p>WBS can also become a good workload balance strategy. You assign the tasks to team member, ensuring that the workload is equally managed across all of your team members. (Also, assigning the tasks can make feel people the ower of their work.)</p>"},{"location":"blog/ProjectMgmt/Tasks-and-Milestones/#steps-to-build-a-wbs","title":"Steps to build a WBS","text":"<p>There are three main steps to follow when creating a WBS:</p> <ol> <li> <p>Start with the high-level, overarching project picture. Brainstorm with your    team to list the major deliverables and milestones. Example: Imagine you are    planning a company event. Your major milestones might include categories    like \u201csecure venue,\u201d \u201cfinalize guest logistics,\u201d and \u201cestablish agenda.\u201d</p> </li> <li> <p>Identify the tasks that need to be performed in order to meet those    milestones. Example: You could break a milestone like \u201csecure venue\u201d down    into tasks like \u201cresearch venues,\u201d \u201ctour and decorate space,\u201d \u201cmake down    payment,\u201d and so on.</p> </li> <li> <p>Examine those tasks and break them down further into sub-tasks. Example: You    could break down a task like \u201ctour and decorate space\u201d further into    sub-tasks like \u201corganize decorating committee,\u201d \u201cpurchase decorations,\u201d    \u201cassign decorating responsibilities,\u201d and so on.</p> </li> </ol> <p></p> <p>Learn more at https://www.lucidchart.com/blog/how-to-create-a-work-breakdown-structure-and-why-you-should</p>"},{"location":"blog/ProjectMgmt/top-level-summary/","title":"Phases of Project (Plant pals Example","text":"<ol> <li>Get started on the Plant Pals Operations and Training plan</li> </ol> <p>In the initiation phase, you made a project charter for the Plant Pals Operations and Training plan. Now you\u2019re ready for the planning phase. You\u2019ll use the charter to create sustainable fulfillment and delivery protocols and support your customer base.</p> <ol> <li>Identify major milestones and assign task owners</li> </ol> <p>First, you\u2019ll define the work your team needs to do for the plan\u2014like sourcing materials and training employees. Creating a work breakdown structure (WBS) diagram and spreadsheet will help you identify and organize major milestones and assign task owners.</p> <ol> <li>Map project schedule and tasks using a Gantt chart</li> </ol> <p>Next, you\u2019ll add those tasks and milestones\u2014along with due dates and durations\u2014to a Gantt chart. This chart helps you clarify and map out task timelines and dependencies, so your team knows what to do at each stage.</p> <ol> <li>Estimate costs and create a budget</li> </ol> <p>Once you\u2019ve set your schedule, it\u2019s time to estimate the costs of your milestones and tasks. Your budget should include both one-time and recurring expenses\u2014as well as a buffer to cover any overages.</p> <ol> <li>Create a Statement of Work (SoW)</li> </ol> <p>When your team hires a vendor to complete a project milestone, you\u2019ll create a Statement of Work (SoW). This legal document defines what you need from the vendor (and what they need from you), so everyone knows what\u2019s expected.</p> <ol> <li>Create a risk management plan</li> </ol> <p>Next, you\u2019ll assess potential risks to the budget and schedule, like staffing shortages or shipping delays. Identifying, evaluating, and preparing for specific risks helps you keep the project on track if things go wrong.</p> <ol> <li>Create a communication plan</li> </ol> <p>When it\u2019s time to train employees, you\u2019ll need to manage various communications among stakeholders. Your communication plan will track senders and recipients, communication goals, key dates, and other details. That way, everyone gets the right information at the right time.</p> <ol> <li>Organize the project artifacts</li> </ol> <p>Finally, to keep your project artifacts organized, you\u2019ll create a project plan in a central location. Your team members and stakeholders can use it to find project documents, and you can refer to it when you plan future projects.</p>"},{"location":"blog/2023/11/30/adding-a-badge-to-your-project/","title":"Adding a badge to your project","text":""},{"location":"blog/2023/11/30/adding-a-badge-to-your-project/#title-vibe-code-the-what-why-and-how-and-when-to-hit-the-brakes-date-2024-01-31","title":"title: \"Vibe Code? The What, Why, and How (And When to Hit the Brakes)\" date: 2024-01-31","text":""},{"location":"blog/2023/11/30/adding-a-badge-to-your-project/#vibe-code-the-what-why-and-how-and-when-to-hit-the-brakes","title":"Vibe Code? The What, Why, and How (And When to Hit the Brakes)","text":"<p>What is Vibe Coding? At its heart, vibe coding is about using AI to generate code from a high-level intent or \"vibe.\" Think of it less like a co-pilot and more like an automated sidekick. You describe a function or a script, the AI generates the code, and you run it. You're less focused on the syntax and more on the desired outcome. It\u2019s a workflow of describe-generate-run-refine.</p> <p>This is a stark contrast to responsible AI-assisted development, where the human developer remains firmly in the driver's seat, meticulously reviewing and guiding every line of code. Vibe coding is fast, fluid, and often done with the explicit goal of getting a quick result, sometimes with the intent to throw the code away later.</p> <p>When to Ride the Vibe \ud83c\udfc4 Not all projects are created equal. Vibe coding is a superpower for the right task.</p> <p>For Developers: Rapid Prototyping: Got a weekend idea for a simple web app or a data script? Vibe code it. You can spin up a proof-of-concept in hours, not days.</p> <p>Automating Repetitive Tasks: Need a Python script to rename files or parse some logs? A simple prompt like \"write a Python function to read a CSV file\" can save you the boilerplate.</p> <p>Learning a New Library: Want to see how a new library works? Ask an AI to generate a simple example. It's like having a personalized, instant documentation assistant.</p> <p>When to Hit the Brakes \ud83d\uded1 Just as a sports car is a bad choice for a family road trip, vibe coding has its limits. This is where it gets critical for tech leads and project managers.</p> <p>For Tech Leads and Project Managers: Critical Systems: Never, ever vibe code mission-critical or security-sensitive applications. The code generated might have unknown flaws, and the cost of debugging or a security breach will far outweigh the speed benefits.</p> <p>Long-term Projects: If a project needs to be maintained for months or years, a vibe-coded mess will become a nightmare. It will accumulate technical debt that cripples the team and makes scaling impossible.</p> <p>Ensuring Code Quality: Vibe-coded solutions often lack documentation, modularity, and proper error handling. This can lead to an \"entropy loop\" where every fix introduces more problems.</p> <p>Common Vibe-Coding Mistakes (And How to Fix Them) The true danger isn't the AI\u2014it's the over-reliance on it. Here are some pitfalls to watch out for, with actionable advice for everyone on the team.</p> <ol> <li>The Security Trap \ud83d\udd12 The Mistake: Blindly accepting AI-generated code that    contains vulnerabilities. In one notable case, an AI assistant naively used    eval() on user input, creating a critical arbitrary code execution    vulnerability. Another common mistake is hardcoding API keys directly into a    script.</li> </ol> <p>Fix: Developers, maintain a \"human in the loop\" mindset. Always    review code for common security flaws like insecure input handling. Tech    leads, mandate static analysis tools and code reviews for any AI-generated    code, no matter how small.</p> <ol> <li>The Technical Debt Vortex \ud83c\udf2a\ufe0f The Mistake: Treating a vibe-coded prototype as    a production-ready solution. The code works, but it's a tangled mess that's    impossible to debug or extend.</li> </ol> <p>Fix: Developers, refactor aggressively.    If a prototype is promising, treat it as pseudo-code and rewrite it with    proper structure. Project managers, plan for a \"refactoring phase\" in your    sprints. The AI got you 80% there; now build the last, most crucial 20%    responsibly.</p> <ol> <li>The Skills Erosion \ud83e\udde0 The Mistake: Over-relying on AI to the point where    developers stop understanding the fundamentals. You lose the ability to    debug complex issues because you never truly learned how the code works.</li> </ol> <p>Fix: Developers, use AI as a tool to explore, not a crutch to lean on.    Always ask the AI why it made a certain choice. Tech leads, foster a culture    of learning. Encourage pair programming and discussions on how to improve    AI-generated code.</p>"},{"location":"blog/2023/11/30/adding-a-badge-to-your-project/","title":"Adding a badge to your project","text":""},{"location":"blog/2023/11/30/adding-a-badge-to-your-project/#title-dos-and-donts-with-vibe-coding-date-2024-01-31","title":"title: \"DO's and DOnt's with Vibe Coding\" date: 2024-01-31","text":""},{"location":"blog/2023/11/30/adding-a-badge-to-your-project/#dos-and-donts-with-vibe-coding","title":"DO's and DOnt's with Vibe Coding","text":"<p>Do's Do experiment with different models. Different LLMs have varying strengths and weaknesses, and you might need to try a few to find the right one for your specific coding problem.</p> <p>Do treat the AI as a search tool. LLMs excel at finding and recalling information from their vast training data, such as obscure documentation or code snippets.</p> <p>Do use the AI for simple, repetitive tasks. The article suggests AI can be helpful for basic programming chores.</p> <p>Don'ts Don't trust the LLM completely. The article warns that LLMs can provide incorrect information and even \"hallucinate\" non-existent code or URLs.</p> <p>Don't treat the LLM like a \"dumpster.\" Avoid dumping large blocks of code on the AI, as this can be inefficient, costly, and even confuse the model.</p> <p>Don't assume all models are the same. Each LLM has a unique internal structure, parameter count, and training data, which can significantly affect its performance.</p> <p>Don't ignore the costs. AI tools charge by the token, and repetitive requests or large inputs can lead to surprisingly high costs.</p> <p>Don't hand over full control. The article highlights the risk of trusting an LLM with critical tasks, as their inherent randomness can lead to unpredictable and destructive outcomes.</p> <p>Don't expect the AI to \"think\" like a human. LLMs are clever mimics and excellent at information retrieval, but they are not always good at deep synthesis or providing novel insights.</p> <p>Don't create inconsistent code. The randomness in LLM output can lead to a \"patchwork quilt\" of different coding styles, making the codebase messy and hard to maintain.</p> <p>Source: https://www.infoworld.com/article/4029093/9-habits-of-the-highly-ineffective-vibe-coder.html</p>"},{"location":"google-cloud-gemini-cookbook/","title":"Google Cloud - Gemini Cookbook","text":""},{"location":"google-cloud-gemini-cookbook/#introduction","title":"Introduction","text":"<p>This cookbook is a collection of recipes for using the Google Cloud platform.</p>"},{"location":"google-cloud-gemini-cookbook/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Google account with access to the Google Cloud Platform.</li> <li>A valid API key or service account credentials.</li> <li>A working Python environment (Python &gt;= 3.8).</li> </ul>"},{"location":"google-cloud-gemini-cookbook/#tools","title":"Tools","text":"<ul> <li>Google Cloud Gemini SDK to access the Gemini API.</li> <li>Streamlit for building the user interface.</li> <li>Cloud Run to deploy the app.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/#lessons","title":"Lessons","text":"<ul> <li>Cookbook Lesson 01: Build a <code>Hello World</code> app with Gemini, Streamlit &amp; Google Cloud Run \ud83d\ude80</li> <li>Cookbook Lesson 02: Deploy Your AI Chatbot to Google Cloud Run: Go Live! \u2601\ufe0f</li> <li>Cookbook Lesson 03  Build Your First Context-aware Gemini Chatbot in Minutes: The Secret to Speed and Relevance! \u26a1</li> <li>Cookbook Lesson 04: \ud83d\udd13Unlock Enterprise AI: Grounding Gemini with RAG and Google Cloud Search</li> <li>Cookbook Lesson 05: Review - Five Takeaways to enhance your Gemini Apps</li> </ul>"},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/","title":"Internal cookbook plan","text":""},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#vision-executive-summary","title":"Vision &amp; Executive Summary","text":"<p>This project is a cookbook-style series designed to teach developers and AI enthusiasts how to build practical, real-world applications using Google Cloud's Gemini models. Through a series of hands-on blog posts and a central GitHub repository, this guide will provide clear, step-by-step instructions, making generative AI accessible even to those with limited prior experience. The goal is to empower builders, foster a collaborative community, and showcase the power of Gemini.</p>"},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#guiding-principles","title":"Guiding Principles","text":"<ul> <li>Practical First: Focus on hands-on examples and code snippets that solve   real problems.</li> <li>Clarity and Simplicity: Provide clear, step-by-step instructions that are   easy to follow.</li> <li>Gemini Focused: Deep-dive into Google Cloud Gemini, its specific   features, and its ecosystem.</li> <li>Fundamental Concepts: Cover the necessary foundational knowledge to use   Gemini effectively.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#questions","title":"Questions","text":"<ul> <li>Why is the goal ?</li> <li>What is the meaning or end goal ?</li> <li>Is it really worth doing it ?</li> <li>Who is asking for it ?</li> </ul>"},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#target-audience","title":"Target Audience","text":"<p>This series is for developers, AI enthusiasts, and anyone interested in learning how to build practical AI applications with Gemini.</p>"},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#content-outline-lesson-plan","title":"Content Outline &amp; Lesson Plan","text":"<p>The series will be released as a sequence of lessons, each building upon the last.</p> Lesson Lesson Title Objective Core Concepts Tech Stack Actionable Items Questions Answered by this Blog Post 1     Hello World Application Learn how to package your application and deploy     Google Cloud Run     Streamlit, Python     2     Build and Deploy a Gemini Chatbot in 15 Minutes <p> &gt;&gt;&gt;&gt;&gt;GDCALERT:Found UNSUPPORTED element which lacks an apps script API.&gt;&gt;&gt;&gt;&gt; <p> Medium | Github Learn how to build and deploy a fully functional chatbot with Gemini and Streamlit in under 15 minutes, just in time for that last-minute demo.     Streamlit Chatbot, Text Generation, Chat history management, Cloud Run     Gemini 2.5 Flash, Python, google-genai SDK, Streamlit, Gemini Code/Jules (Optional)     Create a 5-second GIF of the entire process. Develop a \"Demo Day\" scenario to frame the tutorial. Incorporate Gemini Code/Jules for faster code generation.     How to build a chatbot with Gemini and Streamlit? What is the fastest way to build and deploy a Gemini-powered application? How to create a quick, interactive demo for a presentation? How to use Gemini Code/Jules to accelerate development?     3     Build a Context Aware Chatbot <p> Medium | Github \ud83d\ude80 Build Your First Context-aware Gemini Chatbot in Minutes: The Secret to Speed and Relevance! \u26a1- Part 1     System Instructions; In Context Learning; Context Caching     Gemini 2.5 Flash     4     Build a Context Aware Chatbot <p> RAG; Grounding; <p> Medium | Github \ud83d\ude80 Build Your First Context-aware Gemini Chatbot in Minutes: The Secret to Speed and Relevance! \u26a1- Part 2     Review and Recap     5     Building an Agent with the Agents Development Kit (ADK)     Introduce the fundamentals of the Google AI Development Kit and build a simple agent.     Agent basics, tool definition and usage.     Google ADK, Gemini 1.5 Flash. \\  \\ Ollama Example Create a simple agent that can perform a specific task, like a calculator or a weather checker.     What is the Google AI Development Kit (ADK)? How to build a simple agent with the ADK? How to define and use tools within an agent?     6     Enhancing the Chatbot with Memory     Add conversational memory to the chatbot to enable more natural and context-aware interactions.     Chat history management, context passing, state management.     Vertex AI Memory Bank     Implement a memory solution to store and retrieve data. <p> &gt; Conversation history. <p> &gt; Key Conversation details like User Preferences     How to add memory to a chatbot? How to manage chat history and context? What is Vertex AI Memory Bank and how to use it?     7     Integrating Open Models and Memory with Gemma and MemZero     Explore using open-source models like Gemma and an open memory bank for specialized tasks and data control.     Integrating local/open-source models, working with open memory solutions.     Gemma, Mem0ai Integrate Gemma as the language model and MemZero as the memory bank in the chatbot.     How to use open-source models like Gemma? How to integrate an open memory bank like MemZero? What are the benefits of using open models and memory?     8     Integrating an External API with Function Calling     Empower Gemini to interact with a simple, external API to perform a specific action.     Basic tool definition, function calling for a single tool.     Integrate a public API (e.g., a weather API) and have the agent use it to answer user queries.     What is function calling? How to integrate an external API with Gemini? How to define a tool for a single API?     9     Building a Multi-Tool Agent     Create a more advanced agent that can choose between multiple tools to accomplish a task.     Advanced tool definition, routing between multiple functions.     Build an agent that can use multiple tools (e.g., a calculator, a calendar, and a search engine) to answer complex queries.     How to build an agent that can use multiple tools? How to define and route between multiple functions?     10     Introduction to RAG with a Single Document     Build a basic RAG system that can answer questions from a single PDF or text file.     Document loading, basic chunking, vector embeddings with a local vector store.     Build a RAG system that can answer questions about a specific document.     What is Retrieval-Augmented Generation (RAG)? How to build a basic RAG system? How to load, chunk, and embed a single document?     11     Scaling RAG with a Vector Database     Enhance the RAG system to handle a larger knowledge base by using a dedicated vector database.     Vector database setup (e.g., ChromaDB, Pinecone), efficient semantic search over a large corpus.     Scale the RAG system to handle a large collection of documents by using a vector database.     How to scale a RAG system? How to set up and use a vector database like ChromaDB or Pinecone? How to perform efficient semantic search over a large corpus?     12     Containerizing an AI Application with Docker     Package a Gemini application into a Docker container for portability and consistent deployment.     Dockerfile creation, building and running a Docker image.     Create a Dockerfile for the Gemini application and build a Docker image.     What is Docker and why is it useful for AI applications? How to create a Dockerfile for a Gemini application? How to build and run a Docker image?     13     Deploying to Google Cloud Run     Deploy the containerized application to Google Cloud Run for a scalable, serverless solution.     Cloud Run deployment, managing environment variables and secrets.     Deploy the Dockerized Gemini application to Google Cloud Run.     What is Google Cloud Run? How to deploy a containerized application to Cloud Run? How to manage environment variables and secrets in Cloud Run?     Monitoring and Logging for AI Applications     Implement basic monitoring and logging to track the performance and behavior of the deployed application.     Google Cloud's operations suite (formerly Stackdriver), custom logging within the application.     Implement monitoring and logging for the deployed Gemini application using Google Cloud's operations suite.     How to monitor and log an AI application? What is Google Cloud's operations suite? How to implement custom logging in a Gemini application?     <p>To consider:</p> <ul> <li>A2A Protocol</li> <li>https://www.youtube.com/watch?v=Fbr_Solax1w</li> <li>http://goto.google.com/a2a-slides</li> <li>Observability</li> <li>Cloud Logging &amp; (open source version like self hosted ELK)</li> </ul>"},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#distribution-community-strategy","title":"Distribution &amp; Community Strategy","text":"<ul> <li>Source of Truth: A public GitHub repository will host all code,   resources, and drafts.</li> <li>Primary Publications: Blog posts will be published on Medium.com and   Dev.to to reach a broad developer audience.</li> <li>Community Engagement: Announcements, key takeaways, and discussions will   be shared on X (formerly Twitter) and LinkedIn to foster community   interaction and feedback.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#potential-impact","title":"Potential Impact","text":"<ul> <li>Empower Developers: Lower the barrier to entry for building and deploying   AI-powered applications.</li> <li>Foster Community: Create a hub for Gemini users to share knowledge,   collaborate, and get feedback.</li> <li>Showcase Gemini: Highlight the versatility and power of Gemini for   solving real-world problems.</li> <li>Success Metrics: Track GitHub stars/forks, blog post views/claps, social   media engagement, and community contributions.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#success-metrics","title":"Success Metrics","text":"<ul> <li>Measure user traffic in blog posts Medium.com and   Dev.to</li> <li>Measure user traffic in github repository as stars, clones and contributions.</li> <li>Measure user comments in announcements posts on Linkedin &amp; X.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#guidelines-for-lesson-content-format","title":"Guidelines for Lesson Content Format","text":""},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#1-content-structure-sections","title":"1. Content Structure / Sections","text":"<p>Each lesson should follow a consistent narrative flow, moving from introduction to practical application and deployment.</p> <ul> <li>Catchy Title &amp; Hook:</li> <li>A compelling, action-oriented title.</li> <li>A \"hook\" scenario or problem statement to immediately engage the reader.</li> <li>(Optional, but encouraged) A GIF animation placeholder to visualize the     core concept or speed of development.</li> <li>\"What You'll Learn\" Section:</li> <li>Clearly list the key learning objectives for the lesson.</li> <li>Use bullet points for readability.</li> <li>Include relevant emojis.</li> <li>\"Prerequisites\" Section:</li> <li>List any necessary tools, accounts, or prior knowledge required.</li> <li>Use bullet points.</li> <li>Include relevant emojis.</li> <li>Main Content Sections (The Core of the Lesson):</li> <li>Each core concept (e.g., In-Context Learning, System Instructions, Context     Caching, RAG) should have its own dedicated heading.</li> <li>Start with a clear explanation of the concept: what it is, why it's     important, how it works conceptually.</li> <li>Include use cases to illustrate practical applications.</li> <li>Feature \"Tangible Examples\":<ul> <li>For concepts easily shown through interaction, use screenshot   placeholders with clear descriptions of what the screenshot would show   (e.g., \"Imagine a screenshot here...\"). Explain the input and the   expected output clearly.</li> <li>For concepts requiring code demonstration (e.g., System Instructions,   Context Caching, RAG Orchestration), provide code samples (Python for   llm.py and app.py).</li> <li>Clearly indicate which file (llm.py or app.py) the code belongs to.</li> <li>Ensure code blocks are clearly marked with python: and filename/path.</li> <li>Include conceptual diagrams/flowcharts (with clear placeholders if   not generating directly) for complex flows like RAG.</li> </ul> </li> <li>Discuss considerations, benefits, or limitations for each concept.</li> <li>\"Deployment\" Section:</li> <li>Provide a single, consolidated code block for the main Streamlit     application (app.py and llm.py parts combined, or referencing separate     files as demonstrated in the examples).</li> <li>Include the requirements.txt file.</li> <li>Provide clear, step-by-step deployment instructions for Google Cloud     Run (including gcloud commands).</li> <li>Emphasize necessary API key handling and permissions.</li> <li>Conclude with a celebration of the successful deployment.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/internal_cookbook_plan/#2-formatting-and-style-instructions","title":"2. Formatting and Style Instructions","text":"<ul> <li>Tone and Voice: Professional, engaging, and enthusiastic, reflecting a   \"cookbook\" style (practical, easy-to-follow).</li> <li>Clarity and Conciseness: Explain concepts clearly and simply, avoiding   jargon where possible. Get straight to the point.</li> <li>Emoji Usage:</li> <li>Use emojis moderately to add visual appeal and emphasize points.</li> <li>Place them strategically at the beginning or end of headings, bullet     points, or key sentences.</li> <li>Ensure they enhance understanding, rather than cluttering the text.</li> <li>Headings: Use clear, descriptive headings (##, ###) to break down   content.</li> <li>Code Blocks:</li> <li>Always use Markdown code blocks for all code snippets (Python, Bash).</li> <li>Clearly state what the code block represents (e.g., \"Content for app.py\").</li> <li>Crucially, include DO NOT MODIFY THIS BLOCK comments within the code     sections to guide future iterations.</li> <li>Emphasis: Use bolding (**text**) for key terms and concepts.</li> <li>Lists: Use bullet points (* or -) for lists of objectives,   prerequisites, benefits, etc.</li> <li>Placeholders: For content that is implied (like screenshots or GIFs), use   clear markdown comments indicating what should be imagined or added.</li> <li>Cross-Referencing: Where relevant, refer back to previous lessons (e.g.,   \"As seen in Lesson 01...\") for continuity.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-01/","title":"Cookbook Lesson 01: \ud83d\ude80 Build a <code>Hello World</code> app with Gemini, Streamlit &amp; Google Cloud Run","text":"<p>Welcome to the Google Cloud Gemini Cookbook! In this very first lesson, we're going to embark on an exciting journey: taking your Python code from a simple idea to a live web application in minutes. Forget complex setups; with Streamlit and Google Cloud Run, deploying your first web app is incredibly fast and fun! \u2728</p> <p>This lesson is part of the Google Cloud - Gemini Cookbook (GitHub Link).</p>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#what-youll-learn","title":"What You'll Learn \ud83c\udf93","text":"<p>This lesson focuses on the essentials of getting a web application up and running quickly:</p> <ol> <li>Build a \"Hello World\" with Streamlit: Discover how effortlessly you can    create interactive web apps using just Python. Streamlit handles all the    front-end magic for you! \ud83d\udc0d</li> <li>Deploy to Google Cloud Run: Learn to take your Streamlit app and deploy    it as a scalable, serverless container on Google Cloud Run. This means your    app can handle traffic effortlessly, and you only pay for what you use! \u2601\ufe0f\ud83d\udcb8</li> </ol> <p>By the end of this lesson, you'll have a fully functional web application accessible via a URL, demonstrating the incredible speed of modern cloud development. \ud83d\ude80</p>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#prerequisites","title":"Prerequisites \ud83d\udee0\ufe0f","text":"<p>Before we begin, ensure you have the following:</p> <ul> <li>A Google Cloud Project with billing enabled.</li> <li>The <code>gcloud</code> CLI installed and configured.</li> <li>Python 3.8+ installed on your local machine.</li> <li><code>pip</code> (Python package installer).</li> </ul> <p>For development, we recommend using the Google Cloud Shell, which comes pre-installed with the necessary tools.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#what-is-streamlit","title":"What is Streamlit?","text":"<p>Streamlit is an open-source Python framework that makes it easy to create and share beautiful, custom web apps for machine learning and data science. In just a few lines of code, you can build and deploy powerful data apps.</p> <p>While Streamlit is not as feature-rich as full-fledged web frameworks like Django or Flask, its strength lies in its simplicity and ability to create highly interactive applications quickly. This makes it an excellent choice for building demos and prototypes.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#what-is-google-cloud-run","title":"What is Google Cloud Run?","text":"<p>Cloud Run is a fully managed serverless platform that enables you to run stateless containers that are invocable via web requests or Pub/Sub events. You can deploy your code to Cloud Run, and it will automatically scale up or down based on traffic.</p> <p>Here are some of the benefits of using Cloud Run:</p> <ul> <li>Easy to use: Deploy your application with a single command.</li> <li>Serverless: No infrastructure to manage.</li> <li>Scalable: Automatically scales to meet demand.</li> <li>Cost-effective: Pay only for the resources you use.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#local-development-your-streamlit-hello-world","title":"\ud83d\udcbb Local Development: Your Streamlit \"Hello World\"","text":"<p>Let's start by creating a simple Streamlit application locally. Here's how you can do it:</p>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#1-set-up-your-environment","title":"1. Set up your environment","text":"<p>Create a virtual environment and install the required dependencies:</p> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n</code></pre>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#2-create-a-simple-streamlit-app","title":"2. Create a simple Streamlit app","text":"<p>Create a file named <code>streamlit_app.py</code> with the following content:</p> <pre><code>import streamlit as st\n\nst.title(\"Sample AI App\")\n\nst.text(\"This is a sample app.\")\n</code></pre>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#3-run-the-app-locally","title":"3. Run the app locally","text":"<p>To run the app locally, use the following command:</p> <pre><code>streamlit run streamlit_app.py --server.port 8080\n</code></pre> <p>You should see your Streamlit app open in your browser and navigating to <code>http://localhost:8080</code>. Interact with it! This is your app running locally. \ud83d\ude80</p>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#4-deploy-to-cloud-run","title":"4. Deploy to Cloud Run","text":"<p>To deploy your app to Cloud Run, you'll need to create a <code>Procfile</code> and a <code>deploy.sh</code> script.</p> <p>Procfile</p> <p>Create a file named <code>Procfile</code> with the following content:</p> <pre><code>web: streamlit run streamlit_app.py --server.port=8080 --server.address=0.0.0.0 --server.enableCORS=false --browser.gatherUsageStats=false\n</code></pre> <p>This file tells Cloud Run how to start your application.</p> <p>deploy.sh</p> <p>Create a file named <code>deploy.sh</code> with the following content:</p> <pre><code>#!/bin/bash\n# Purpose: To deploy the App to Cloud Run.\n\n# Google Cloud Project ID\nPROJECT=\"your-gcp-project-id\"\n\n# Google Cloud Region\nLOCATION=\"us-central1\"\n\n# Deploy app from source code\ngcloud run deploy simple-app --source . --region=$LOCATION --project=$PROJECT --allow-unauthenticated\n</code></pre> <p>Important: Replace <code>\"your-gcp-project-id\"</code> with your actual Google Cloud Project ID.</p> <p>Now, run the deployment script:</p> <pre><code>bash deploy.sh\n</code></pre> <p>This command will build a container image from your source code, push it to the container registry, and deploy it to Cloud Run. Once the deployment is complete, you'll see a service URL in the output.</p> <p>Congratulations \ud83c\udf89! You have successfully deployed your Streamlit app to Cloud Run.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#cleanup","title":"Cleanup","text":"<p>To avoid incurring future charges, delete the resources you created:</p> <ul> <li>Go to the Cloud Run console and   delete your application.</li> <li>Go to the Container Registry and   delete the container image.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-01/#learn-more","title":"Learn More","text":"<ul> <li>Cloud Run Documentation</li> <li>Streamlit Documentation</li> <li>Authenticating to Cloud Run</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-02/","title":"Cookbook Lesson 02: Deploy Your AI Chatbot to Google Cloud Run: Go Live! \u2601\ufe0f","text":"<p>Welcome to the second lesson in our Gemini Cookbook series! This time, we're diving into the exciting world of conversational AI. You'll learn to build a smart, interactive chatbot using the power of Streamlit and Google's Gemini 2.5 Flash model. We'll be using the official Google Cloud Vertex AI SDK, which has powerful features like chat sessions that give your bot a memory.</p> <p>This lesson is part of the Google Cloud - Gemini Cookbook (GitHub Link).</p>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#what-youll-create","title":"What You'll Create","text":"<p>Get ready to build a sleek, web-based chatbot. With Streamlit as our frontend, your chatbot will connect to the mighty Gemini 1.5 Flash model, enabling you to have dynamic and stateful conversations. It's like having your own personal AI assistant!</p> <p></p>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#what-youll-need","title":"What You'll Need","text":"<p>To get started, make sure you have the following essentials:</p> <ul> <li>A Google Cloud project with the Vertex AI API ready to go.</li> <li>Python 3.8 or a newer version.</li> <li>The <code>pip</code> package manager for installing our dependencies.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#mandatory-steps","title":"Mandatory steps","text":"<p>This is a mandatory steps to access Gemini Models from your Google Cloud Project.</p> <p>I have installed the Gcloud tool and used Application Default Credentials to get the credentials. If you want to run the code in Google Cloud project, then you need to update respective service-account with the required permissions. For details, check out this user-managed service account article.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#lets-get-building","title":"Let's Get Building!","text":"<ol> <li>Get the Code: First, clone the repository and hop into the right    directory:</li> </ol> <p><code>bash    git clone https://github.com/msampathkumar/msampathkumar.github.io.git    cd msampathkumar.github.io/docs/google-cloud-gemini-cookbook/lesson-02</code></p> <ol> <li>Set Up Your Workspace: Create a virtual environment to keep things tidy:</li> </ol> <p><code>bash    python3 -m venv .venv    source .venv/bin/activate</code></p> <ol> <li>Install the Magic: Time to install the necessary Python packages:</li> </ol> <p><code>bash    pip install -r requirements.txt</code></p> <ol> <li>Connect to Google Cloud: Authenticate your local environment to use    Google Cloud services:</li> </ol> <pre><code>gcloud auth application-default login\n</code></pre>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#a-look-under-the-hood","title":"A Look Under the Hood","text":"<p>Let's take a peek at the code that makes our chatbot tick.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#the-chatbot-ui-streamlit_apppy","title":"The Chatbot UI: <code>streamlit_app.py</code>","text":"<p>This file is the heart of our Streamlit app. It's responsible for:</p> <ul> <li>Providing a chat interface for user input.</li> <li>Displaying the response from the model.</li> <li>Maintaining the conversation history.</li> </ul> <p>While you would typically use Streamlit's <code>session_state</code> to store the conversation history manually, the Vertex AI SDK simplifies this. We'll use a <code>ChatSession</code> object from the SDK, which automatically handles the history for us. We just need to store this one object in <code>st.session_state</code> to make our chat stateful.</p> <p>You can see the core logic below:</p> <pre><code>import streamlit as st\nimport llm\n\n# Initialize chat session in Streamlit's session state.\n# This will be run only once, on the first run of the session.\nif \"chat_session\" not in st.session_state:\n    st.session_state.chat_session = llm.start_chat()\n\n# Display chat history from the session state\nfor message in st.session_state.chat_session.history:\n    with st.chat_message(\"assistant\" if message.role == \"model\" else \"user\"):\n        st.markdown(message.parts[0].text)\n</code></pre>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#the-brains-of-the-operation-llmpy","title":"The Brains of the Operation: <code>llm.py</code>","text":"<p>This file handles all the communication with the Gemini 2.5 Flash model. As we are using GenAI SDK, we can use environment variables to set up the required details for authentication. Also, GenAI SDK provides us with <code>Client</code> class which we can use to create a chat session and send messages to the Gemini Model and receive.</p> <pre><code>from google import genai\n\n# Using environment variables to pass essential parameters to the client.\nclient = genai.Client()\n\n# Create chat session\nchat_session = client.chats.create(\"gemini-2.0-flash-lite-001\")\n</code></pre>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#to-run-chatbot-in-cli","title":"To run chatbot in CLI","text":"<pre><code>python llm.py\n</code></pre>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#to-run-streamlit-chatbot","title":"To run streamlit chatbot","text":"<pre><code>streamlit run streamlit_app.py\n</code></pre>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#deploy-the-application","title":"Deploy the application","text":"<p>You can deploy your chatbot to Google Cloud Run and share it with the world.</p> <p>Use the <code>deploy.sh</code> script to package your app into a Docker image and send it to the Google Artifact Registry.</p> <pre><code>./deploy.sh\n</code></pre> <p>The script will then deploy your app to Cloud Run, making it live on the web.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-02/#you-did-it","title":"You Did It!","text":"<p>High five! You've built and deployed a fully functional chatbot with Streamlit and Gemini Pro. You've seen how to use the new Generative AI SDK and its chat features to create a more natural and engaging conversational experience. Now, go ahead and have a chat with your new AI friend!</p>"},{"location":"google-cloud-gemini-cookbook/lesson-03/","title":"Lesson-03","text":""},{"location":"google-cloud-gemini-cookbook/lesson-03/#cookbook-lesson-03-build-your-first-context-aware-gemini-chatbot-in-minutes-the-secret-to-speed-and-relevance","title":"Cookbook Lesson 03 \ud83d\ude80 Build Your First Context-aware Gemini Chatbot in Minutes: The Secret to Speed and Relevance! \u26a1","text":"<p>Scenario: It's Tuesday, July 22, 2025, 12:26 PM CEST. You're a developer, enjoying your morning coffee in Warsaw \u2615, contemplating your next big feature. Suddenly, your director bursts in: \"We need a quick demo of a new, context-aware chatbot for our internal knowledge base \u2013 and the meeting is in 30 minutes! Can you get something ready?\" \ud83e\udd2f</p> <p>Panic? Absolutely not! Not with Gemini and Streamlit. This lesson is your secret weapon to rapidly inject intelligence into your chatbot, focusing on direct, consistent, and reusable context methods that get you up and running with meaningful interactions fast.</p> <p>This lesson is part of the 5 part series Google Cloud - Gemini Cookbook (GitHub Link).</p>"},{"location":"google-cloud-gemini-cookbook/lesson-03/#1-understanding-context-why-its-your-chatbots-superpower","title":"1. Understanding Context: Why It's Your Chatbot's Superpower \ud83e\uddb8\u200d\u2640\ufe0f","text":"<p>Large Language Models (LLMs) like Gemini are incredible, but they're not clairvoyant. Without explicit guidance, their responses can be generic, vague, or even incorrect when faced with specific or domain-sensitive questions. Context is the \"secret sauce\" that transforms a generic LLM into a specialized, helpful chatbot. It's the information you provide to guide the model's understanding and shape its output. \ud83d\udca1</p> <p>Consider a simple chatbot built with Gemini and Streamlit. If you ask it a very specific question without any context, it might struggle.</p> <p>Example: A Generic Chatbot Responding to a Specific Query</p> <p>Let's say your basic Streamlit app simply forwards user input to Gemini. If you ask about an internal project:</p> <pre><code>$ python llm.py\n\nChat session ID: 4383160272\nEnter your question (or 'exit' to quit)\n\nUser: What are the key milestones for Project Alpha in Q3?\n\nModel: I need a little more information to tell you about\n   Project Alpha's Q3 milestones! Could you please tell me \n   more about what \"Project Alpha\" refers to? \ud83d\ude0a\n\n</code></pre> <p>or via chatbot UI:</p> <pre><code>streamlit run streamlit_app.py\n</code></pre> <p></p> <p>This is where context comes in. By providing context, you tell Gemini exactly what \"Project Alpha\" means in your world. \u2728</p>"},{"location":"google-cloud-gemini-cookbook/lesson-03/#2-in-context-learning-icl-guiding-with-examples-instantly","title":"2. In-Context Learning (ICL): Guiding with Examples, Instantly \u2728","text":"<p>In-Context Learning (ICL) is the quickest way to demonstrate a desired output pattern to Gemini. You provide explicit examples directly within your prompt, and Gemini learns from these patterns without needing any fine-tuning. It's like teaching by showing!</p>"},{"location":"google-cloud-gemini-cookbook/lesson-03/#one-shot-learning-a-single-guiding-example","title":"One-Shot Learning: A Single Guiding Example \u261d\ufe0f","text":"<p>For simple tasks, one example might be all you need. You show Gemini a single input-output pair, and it follows that pattern for subsequent queries.</p> <p>Use Case: Simple classification, rephrasing, or straightforward translation. \ud83c\udf10</p> <p>Example: One-Shot Translation</p> <pre><code>User: Translate this English to French.\n      English: Hello.\n      French: Bonjour.\n      English: What is your name?\n      French:\nChatbot (With one-shot example): Quel est votre nom?\n</code></pre> <p></p>"},{"location":"google-cloud-gemini-cookbook/lesson-03/#few-shot-learning-reinforcing-complex-patterns","title":"Few-Shot Learning: Reinforcing Complex Patterns \ud83d\udcda","text":"<p>When the task is more nuanced or requires a specific output format, providing a few examples helps Gemini better grasp the pattern. It's like providing multiple reference points for complex concepts.</p> <p>Use Case: More nuanced categorization, structured data extraction, or adhering to specific stylistic requirements. \ud83d\udccb</p> <p>Example: Few-Shot Sentiment Analysis</p> <pre><code>\nUser: Review: The delivery was fast!\n      Sentiment: Positive.\n\n      Review: The product broke immediately.\n      Sentiment: Negative.\n\n      Review: The customer service was okay, but the delivery was slow.\n      Sentiment:\nChatbot (With few-shot examples): Mixed/Neutral\n</code></pre> <p></p> <p>Considerations: While powerful for quick guidance, ICL consumes tokens with every prompt, which can impact cost and latency for very long examples or many turns. \ud83d\udcb8\ud83d\udc22</p>"},{"location":"google-cloud-gemini-cookbook/lesson-03/#3-system-instructions-setting-your-chatbots-personality-and-rules","title":"3. System Instructions: Setting Your Chatbot's Personality and Rules \ud83d\udcdc","text":"<p>System instructions define your chatbot's overarching persona, tone, and behavioral guardrails. This is a foundational layer of context that applies to all subsequent user turns in a chat session, making Gemini's responses consistent and aligned with your brand or application's requirements. It's like giving your bot a permanent job description! \ud83e\uddd1\u200d\ud83d\udcbb</p> <p>You define the \"rules of engagement\" for your chatbot, ensuring it behaves predictably. \ud83d\udea6</p> <p>Code Sample: llm.py (LLM Interaction Logic)</p> <p>System instructions are defined in the <code>llm.py</code> file.</p> <pre><code>chat_session = client.chats.create(\n   model=MODEL_NAME,\n   config=GenerateContentConfig(\n      system_instruction=[\n       \"You're a helpful Gemini AI Chatbot.\",\n       \"Answer user's questions and use simple and clear language.\"\n       \"When possible, reply to user's question with a single sentence or a few sentences.\",\n       \"Free to use emojis.\"\n       \"Be open and friendly. Don't be afraid to ask questions or clarify things.\",\n      ]\n  ),\n)\n</code></pre>"},{"location":"google-cloud-gemini-cookbook/lesson-03/#4-context-caching-reusing-static-information-efficiently","title":"4. Context Caching: Reusing Static Information Efficiently \ud83d\udce6","text":"<p>Imagine your chatbot needs to be an expert on a fixed set of documents, like internal reports, product manuals, or, in our case, specific research papers. Sending these large documents with every single API call would be slow and expensive. This is where Context Caching becomes a game-changer.</p> <p>Gemini's Context Caching allows you to process and store static, frequently-referenced content once. You then refer to this cached content using a simple, lightweight name in your subsequent API calls. This drastically saves tokens, reduces latency, and lowers costs, especially when dealing with large files.</p> <p>Example Use Case: Efficient retrieval of information from large, static knowledge bases, optimizing token usage, and simplifying your requests to model. \ud83d\udce6</p> <p>Let update our chatbot a chatbot to be expert on the Gemini family of models, using two key research papers as its knowledge base.</p> <ul> <li>Paper 1: Gemini: A Family of Highly Capable Multimodal   Models.(2312.11805v3.pdf)</li> <li>Paper 2: Gemini 1.5: Unlocking multimodal understanding across millions of   tokens of context   (2403.05530.pdf)Instead   of feeding these PDFs to the model repeatedly, we'll cache them and let our   chatbot use that cached knowledge.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-03/#how-it-works-a-two-step-process","title":"How It Works: A Two-Step Process","text":"<p>Step 1: Create the Cache</p> <p>First, you need to upload your static files and create a CachedContent object. This is a one-time operation. You'll save the name of the cache to use in your application later.</p> <p>Full code: https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/genai/content_cache/contentcache_create_with_txt_gcs_pdf.py</p> <pre><code>system_instruction = \"\"\"\nYou are an expert researcher.\nYou always stick to the facts in the sources provided, and never make up new facts.\nNow look at these research papers, and answer the following questions.\n\"\"\"\n\ncache_objects = [\n    Part.from_uri(\n        file_uri=\"gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf\",\n        mime_type=\"application/pdf\",\n    ),\n    Part.from_uri(\n        file_uri=\"gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf\",\n        mime_type=\"application/pdf\",\n    ),\n]\n\ncontent_cache = client.caches.create(\n    model=\"gemini-2.5-flash\",\n    config=CreateCachedContentConfig(\n        contents=[Content(role=\"user\", parts=cache_objects)],\n        system_instruction=system_instruction,\n        display_name=\"example-cache\",\n        ttl=\"86400s\",\n    ),\n)\n</code></pre> <p>Note: Cache is created with a TTL (time to live). After a specific amount of time, the cache will be deleted.</p> <p>Once the cache is created you will a cache name (e.g., cachedContents/f1e2d3c4-a5b6-7890-a1b2-c3d4e5f6a7b8), which we will use with chatbot.</p> <p>Step 2: Use the Cache in Your Chatbot</p> <p>Once the cache is created, you can use it in your chatbot by passing its name in the <code>GenerateContentConfig</code> object. For example:</p> <pre><code>system_instruction = \"...\"\ncache_name = (\"projects/.../locations/us-central1/keyRings/.../cryptoKeys/...\",)\n\nchat_session = client.chats.create(\n    config=GenerateContentConfig(\n        cached_content=cache_name,\n        system_instruction=None if cache_name else system_instruction,\n    )\n)\n</code></pre> <p>Since the Cache has a defined timelimit, it required a little attention to avoid any potential issues. So I hae created a CacheManager to manage the cache, which will automatically clean up expired caches.</p> <p>Here is the content for <code>cache.py</code></p> <p>Examples:</p> <p>Here is the example of not using Context Cache:</p> <p></p> <p>Here is the example of using Context Cache:</p> <p></p>"},{"location":"google-cloud-gemini-cookbook/lesson-03/#to-deploy-this-application-on-google-cloud-run","title":"To Deploy This Application on Google Cloud Run:","text":"<ol> <li>Clone this repository and navigate to the directory</li> </ol> <pre><code>git clone https://github.com/msampathkumar/msampathkumar.github.io.git\ncd docs/google-cloud-gemini-cookbook/lesson-03\n</code></pre> <ol> <li>Setup your virtual environment and install dependencies:</li> </ol> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n</code></pre> <ol> <li>Run the application locally to make sure it works as expected.</li> </ol> <pre><code>streamlit run streamlit_app.py\n</code></pre> <ol> <li>To deploy to Google Cloud Run, you can use the <code>deploy.sh</code> script:</li> </ol> <pre><code>bash deploy.sh\n</code></pre> <p>Github: https://github.com/msampathkumar/msampathkumar.github.io/tree/master/docs/google-cloud-gemini-cookbook</p>"},{"location":"google-cloud-gemini-cookbook/lesson-03/#congratulations","title":"Congratulations \ud83c\udf89 ( \u25e0\u203f\u25e0 )","text":"<p>Congratulations, You've Achieved a Milestone!</p> <p>You successfully deployed a content-aware chatbot application to Google Cloud Run.</p> <p>In the next lesson, we will delve into two more features that will further enhance your chatbot's context awareness:</p> <ol> <li>RAG: Retrieval Augmented Generation (RAG)</li> <li>Grounding: Using Google Search</li> </ol> <p>Let's continue learning and exploring these innovative tools together!</p>"},{"location":"google-cloud-gemini-cookbook/lesson-04/","title":"Lesson-04","text":""},{"location":"google-cloud-gemini-cookbook/lesson-04/#cookbook-lesson-04-unlock-enterprise-ai-grounding-gemini-with-rag-and-google-cloud-search","title":"Cookbook Lesson 04: \ud83d\udd13 Unlock Enterprise AI: Grounding Gemini with RAG and Google Cloud Search \ud83d\ude80","text":"<p>Welcome back! \ud83d\udc4b In Lesson 03, we built fast, relevant chatbots using direct context methods like In-Context Learning \u2728, System Instructions \ud83d\udcdc, and Context Caching \ud83d\udce6. Those are fantastic for quick demos and consistent persona. But what if your chatbot needs to know the latest company sales figures, details from an obscure internal report, or specific client history? That's where Large Language Models (LLMs) hit their limit \u2013 they hallucinate! \ud83d\ude35\u200d\ud83d\udcab</p> <p>Today, we tackle the next frontier: Grounding your Gemini models in real-time, external, and even proprietary data using Retrieval Augmented Generation (RAG), with Google Cloud Search as your powerful engine. \ud83d\udd0d</p> <p>This lesson is part of the 5 part series Google Cloud - Gemini Cookbook (GitHub Link).</p>"},{"location":"google-cloud-gemini-cookbook/lesson-04/#1-grounding-llms-combating-hallucinations-with-external-knowledge","title":"1. Grounding LLMs: Combating Hallucinations with External Knowledge \ud83d\udee1\ufe0f","text":"<p>LLMs are brilliant pattern matchers, trained on vast amounts of internet data. However, their knowledge is frozen at their last training cut-off date. They don't have real-time access to the internet, nor do they inherently know your company's internal documents, recent sales data, or specific client interactions. When asked about such information, they might:</p> <ul> <li>Refuse to answer: \"I don't have information on that.\" \ud83e\udd37\u200d\u2640\ufe0f</li> <li>Generate generic or outdated information: \"According to general industry   trends...\" \ud83d\uddd3\ufe0f</li> <li>\"Hallucinate\": Make up plausible-sounding but entirely false information.   This is the most dangerous! \ud83d\udea8</li> </ul> <p>Example: A Chatbot Hallucinating on Project Status</p> <p>Let's revisit our chatbot. If you ask about specific, latest information:</p> <pre><code>User: What is the status of our CRM project - Alpha?\n\nModel: I'm sorry, but I don't have access to specific project details like the status of your CRM project Alpha. \ud83d\ude1f I can only provide general information.\n\nUser: What is today's date ?\n\nModel: Today's date is June 16, 2024. \ud83d\udcc5\n</code></pre> <p>This is a problem. In enterprise settings, accuracy is paramount. We need a way to connect Gemini to our actual, verifiable knowledge. This is called grounding. \ud83c\udf31</p>"},{"location":"google-cloud-gemini-cookbook/lesson-04/#2-introduction-to-retrieval-augmented-generation-rag-your-llms-research-assistant","title":"2. Introduction to Retrieval Augmented Generation (RAG): Your LLM's Research Assistant \ud83e\uddd1\u200d\ud83c\udf93","text":"<p>Retrieval Augmented Generation (RAG) is an architectural pattern that solves the hallucination problem by giving LLMs access to external, up-to-date, and domain-specific information.</p> <p>Think of RAG as giving your LLM a brilliant research assistant: \ud83e\uddd0</p> <ol> <li>Retrieve: When you ask a question, the \"research assistant\" first    searches a vast library (your knowledge base) for relevant documents or    snippets. \ud83d\udcda</li> <li>Augment: It then takes the most relevant findings and gives them to the    LLM. \ud83e\udde9</li> <li>Generate: Finally, the LLM uses this specific, retrieved information    (along with your original query) to formulate an accurate and grounded    response. \u2705</li> </ol> <p>Key Components of a RAG System:</p> <ul> <li>Knowledge Base: Your source of truth \u2013 internal documents, databases,   websites, etc. \ud83d\udcc1</li> <li>Retriever: A system (like a vector database combined with an embedding   model, or a powerful search engine like Google Cloud Search) that can quickly   find the most relevant pieces of information from your knowledge base based   on a query. \ud83d\udd0e</li> <li>Generator: The LLM (Gemini) that synthesizes the answer using the   retrieved context. \ud83e\udde0</li> </ul> <p>Benefits of RAG:</p> <ul> <li>Factuality: Grounding responses in real data dramatically reduces   hallucinations. \u2705</li> <li>Currency: LLMs can answer questions about information that wasn't in   their training data or is constantly changing. \u23f0</li> <li>Domain-Specific Knowledge: Access to proprietary or niche topics. \ud83d\udcbc</li> <li>Attribution: Potential to show users where the information came from   (e.g., \"Source: Policy Manual v2.1\"). \ud83d\udd17</li> </ul> <p>RAG vs. Context Cache: A Crucial Distinction \ud83d\udea8</p> <p>It's vital to differentiate RAG from Context Caching (Lesson 03).</p> <ul> <li>Context Cache: Reuses small, static pieces of pre-loaded or   conversational context. It's about efficiency for fixed data, avoiding   redundant token usage. Think of it as a persistent \"sticky note\" or   short-term memory for repeated instructions or small data blocks. \ud83d\udcdd</li> <li>RAG: Dynamically retrieves specific, often large, and always relevant   chunks of information from a vast, external knowledge base on demand for   each query. It's about expanding the LLM's factual knowledge with new,   current, or private data. \ud83c\udf10</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-04/#3-application-architecture","title":"3. Application Architecture","text":"<p>This application is designed to be a flexible and extensible chatbot that can leverage different grounding techniques. Here's a breakdown of the core components:</p> <pre><code>graph TD\n    subgraph User Interface\n        A[streamlit_app.py]\n    end\n\n    subgraph Core Logic\n        B(llm.py)\n    end\n\n    subgraph Optional Add-ons\n        C[cache.py]\n        D[rag.py]\n    end\n\n    A -- \"Initializes and calls\" --&gt; B\n    B -- \"Optionally uses\" --&gt; C\n    B -- \"Optionally uses\" --&gt; D\n</code></pre> <p>Core Application Logic:</p> <ul> <li><code>streamlit_app.py</code> (UI): This is the user-facing component of the   application, built with Streamlit. It provides the chat interface, handles   user input, and displays the LLM's responses. It's the \"skin\" of our   application.</li> <li><code>llm.py</code> (The Brain): This module is the central nervous system of our   chatbot. It's responsible for all interactions with the Gemini API. It takes   the user's prompt, and based on the selected mode (Default, Context Cache, or   RAG), it constructs the appropriate request to the Gemini model.</li> <li><code>cache.py</code> (Optional Battery): This module manages the Context Cache.   When the \"Use Context Cache\" option is selected, <code>llm.py</code> uses this module to   create and manage a cache of context, which can be reused across   conversations to improve speed and reduce costs.</li> <li><code>rag.py</code> (Optional Battery): This module handles the Retrieval-Augmented   Generation (RAG) functionality. When the \"Use RAG as Tool\" option is   selected, <code>llm.py</code> uses this module to create and manage a RAG corpus. This   allows the LLM to retrieve information from a knowledge base to answer   questions.</li> </ul> <p>Code Links:</p> <ul> <li>streamlit_app.py</li> <li>llm.py</li> <li>cache.py</li> <li>rag.py</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-04/#4-rag-implementation-flow","title":"4. RAG Implementation Flow","text":"<p>Here\u2019s a more detailed look at how the RAG process works within our application when the \"Use RAG as Tool\" option is enabled:</p> <pre><code>sequenceDiagram\n    participant User\n    participant Streamlit UI (streamlit_app.py)\n    participant LLM Brain (llm.py)\n    participant RAG Corpus (rag.py)\n    participant Gemini API\n\n    User-&gt;&gt;Streamlit UI (streamlit_app.py): Enters a prompt\n    Streamlit UI (streamlit_app.py)-&gt;&gt;LLM Brain (llm.py): Sends prompt to get chat session\n    LLM Brain (llm.py)-&gt;&gt;RAG Corpus (rag.py): Initializes RAG corpus\n    RAG Corpus (rag.py)--&gt;&gt;LLM Brain (llm.py): Returns RAG corpus name\n    LLM Brain (llm.py)-&gt;&gt;Gemini API: Creates chat session with RAG tool\n    Gemini API--&gt;&gt;LLM Brain (llm.py): Returns chat session\n    LLM Brain (llm.py)--&gt;&gt;Streamlit UI (streamlit_app.py): Returns chat session\n    Streamlit UI (streamlit_app.py)-&gt;&gt;LLM Brain (llm.py): Sends user prompt\n    LLM Brain (llm.py)-&gt;&gt;Gemini API: Sends prompt to Gemini\n    Gemini API-&gt;&gt;RAG Corpus (rag.py): Retrieves relevant documents\n    RAG Corpus (rag.py)--&gt;&gt;Gemini API: Returns documents\n    Gemini API--&gt;&gt;LLM Brain (llm.py): Generates response based on retrieved documents\n    LLM Brain (llm.py)--&gt;&gt;Streamlit UI (streamlit_app.py): Returns grounded response\n    Streamlit UI (streamlit_app.py)--&gt;&gt;User: Displays response\n</code></pre>"},{"location":"google-cloud-gemini-cookbook/lesson-04/#5-application-screenshots","title":"5. Application Screenshots","text":"<p>Youtube: https://youtu.be/JIx4Fr4V6Mw</p>"},{"location":"google-cloud-gemini-cookbook/lesson-04/#conclusion","title":"Conclusion","text":"<p>This lesson demonstrated how to ground Gemini models with external knowledge using RAG. By leveraging RAG, we can build more accurate, factual, and useful AI applications that can reason about private and real-time data.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-04/rag_dataset/project_alpha/","title":"Project Alpha","text":""},{"location":"google-cloud-gemini-cookbook/lesson-04/rag_dataset/project_alpha/#project-summary","title":"Project Summary","text":"<p>Project Alpha is a next-generation customer relationship management (CRM) platform designed to revolutionize how businesses interact with their customers. It leverages artificial intelligence and machine learning to provide predictive analytics, automate sales workflows, and offer personalized customer experiences.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-04/rag_dataset/project_alpha/#goals","title":"Goals","text":"<ul> <li>To increase customer retention by 20% within the first year of launch.</li> <li>To reduce the sales cycle duration by 15%.</li> <li>To improve sales team productivity by 30%.</li> <li>To provide a single, unified view of the customer across all touchpoints.</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-04/rag_dataset/project_alpha/#team","title":"Team","text":"<ul> <li>Project Manager: Alice Johnson</li> <li>Lead Developer: Bob Williams</li> <li>Frontend Developer: Charlie Brown</li> <li>Backend Developer: Diana Prince</li> <li>UI/UX Designer: Eve Adams</li> <li>QA Engineer: Frank Miller</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-04/rag_dataset/project_alpha/#timeline","title":"Timeline","text":"<ul> <li>Phase 1: Discovery &amp; Planning - Q1 2023 (Completed)</li> <li>Phase 2: Design &amp; Prototyping - Q2 2023 (Completed)</li> <li>Phase 3: Development &amp; Implementation - Q3-Q4 2023 (In Progress)</li> <li>Phase 4: Testing &amp; QA - Q1 2024</li> <li>Phase 5: Launch &amp; Deployment - Q2 2024</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-04/rag_dataset/project_alpha/#status","title":"Status","text":"<p>Current Status: In Progress</p> <p>We are currently in the middle of Phase 3. The backend team is focused on building out the core APIs for contact management and analytics. The frontend team is developing the main dashboard and reporting components.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-04/rag_dataset/project_alpha/#technologies","title":"Technologies","text":"<ul> <li>Frontend: React, Redux, TypeScript</li> <li>Backend: Python, Django, PostgreSQL</li> <li>AI/ML: TensorFlow, scikit-learn</li> <li>Infrastructure: Google Cloud Platform (GCP), Docker, Kubernetes</li> </ul>"},{"location":"google-cloud-gemini-cookbook/lesson-04/rag_dataset/rag_intro/","title":"Rag intro","text":"<p>Retrieval-Augmented Generation (RAG) is a technique that enhances the capabilities of large language models (LLMs) by allowing them to access and incorporate external data sources when generating responses. Here's a breakdown:</p> <p>What it is:</p> <ul> <li>Combining Retrieval and Generation:</li> <li>RAG combines the strengths of information retrieval systems (like search     engines) with the generative power of LLMs.</li> <li>It enables LLMs to go beyond their pre-trained data and access up-to-date     and specific information.</li> <li>How it works:</li> <li>When a user asks a question, the RAG system first retrieves relevant     information from external data sources (e.g., databases, documents, web     pages).</li> <li>This retrieved information is then provided to the LLM as additional     context.</li> <li>The LLM uses this augmented context to generate a more accurate and     informative response.</li> </ul> <p>Why it's helpful:</p> <ul> <li>Access to Up-to-Date Information:</li> <li>LLMs are trained on static datasets, so their knowledge can become     outdated. RAG allows them to access real-time or frequently updated     information.</li> <li>Improved Accuracy and Factual Grounding:</li> <li>RAG reduces the risk of LLM \"hallucinations\" (generating false or     misleading information) by grounding responses in verified external data.</li> <li>Enhanced Contextual Relevance:</li> <li>By providing relevant context, RAG enables LLMs to generate more precise     and tailored responses to specific queries.</li> <li>Increased Trust and Transparency:</li> <li>RAG can provide source citations, allowing users to verify the information     and increasing trust in the LLM's responses.</li> <li>Cost Efficiency:</li> <li>Rather than constantly retraining large language models, RAG allows for the     introduction of new data in a more cost effective way.</li> </ul> <p>In essence, RAG bridges the gap between the vast knowledge of LLMs and the need for accurate, current, and contextually relevant information.</p> <p>Source: https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/rag-engine/intro_rag_engine.ipynb</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/","title":"Index","text":""},{"location":"google-cloud-gemini-cookbook/lesson-05/#cookbook-lesson-05-review-five-takeaways-to-enhance-your-gemini-apps","title":"Cookbook Lesson 05: Review - Five Takeaways to enhance your Gemini Apps","text":"<p>Welcome to Lesson 05 of my Gemini Cookbook series :)</p> <p>The potential of Gemini is limitless, but unlocking its true power requires more than just a \u2018hello world\u2019 app. It demands a strategic approach to performance, cost, and design. In this lesson 05, we\u2019ll transform that potential into reality by exploring 5\ufe0f\u20e3 key takeaways that will elevate your Gemini applications to the next level.</p> <p>In Lessons 01 through 04, we covered essential topics, from building a \u201chello world\u201d app to creating powerful, context-aware chatbots. In this Lesson 05, we\u2019ll do a quick recap of those earlier lessons and then dive into some important tips and takeaways for building great Gemini features applicable to most users.</p> <p>This lesson is the last part of the 5 part series Google Cloud - Gemini Cookbook (GitHub Link).</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#takeaway-01-multi-layered-application","title":"Takeaway 01: Multi-Layered Application","text":"<p>Let me quote from a Google Developer Advocate.</p> <p>\u201cTo effectively monitor your agent, it\u2019s best to adopt a practical, layered approach. Here\u2019s a guide to setting up observability at every stage of the development lifecycle.\u201d - Alvin Prayuda Juniarta Dwiyantoro</p> <p>Building an application and its features can become a cascading challenge, especially when you aim for an app that can be used, maintained, updated, and deployed to production environments. As mentioned in the quote, building applications with a layered approach can help streamline the overall development flow.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#flow-chart","title":"Flow chart","text":"<p>Lesson 04 Github-Link</p> <p></p> <p>This tutorial series built a sophisticated chatbot over four lessons.</p> <ul> <li>Lesson 01: We started with streamlit_app.py to create a basic \u201chello world\u201d page and learned deployment fundamentals.</li> <li>Lesson 02: We developed llm.py, the chatbot\u2019s \u201cbrain,\u201d using Google\u2019s GenAI SDK, and designed the user interface for interactive chat sessions.</li> <li>Lesson 03: We added contextual awareness using System Instructions and a Context Cache to maintain coherent conversations.</li> <li>Lesson 04: We expanded the chatbot\u2019s context to external resources like Google Search and external data stores via Retrieval Augmented Generation (RAG).</li> </ul> <p>To maintain simplicity, Lessons 03 and 04 utilize a layered architecture (for code), adding new features as distinct modules. This actually differs with the initial approach, where a single file facilitated early development. As features expanded, I realized the benefits of dedicated modules like RAG.py and Cache.py over modifying existing files, which significantly streamlined development, testing, and debugging.</p> <p>This layered approach proved effective in our application. The following sections detail further takeaways from my experiments and explorations.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#takeaway-02-improve-your-speed","title":"Takeaway 02: Improve your speed","text":"<p>Large Language Models (LLMs) are extensive software applications that utilize significant CPU, memory, and network resources. Much like services such as BigQuery or Cloud SQL, these models are globally hosted, serving users worldwide. In this section, we will observe how you can improve model responses speed.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#021-global-endpoints-ge","title":"021 Global Endpoints (GE):","text":"<p>This section presents my personal explorations and hypotheses.</p> <p>It\u2019s common to assume that proximity to the LLM\u2019s physical location ensures optimal performance. While reduced network latency is a factor, it doesn\u2019t account for the entire picture. LLMs operate as shared services, inherently utilizing a first-in, first-out queuing system. Therefore, the ideal location selection hinges on the equation: min_response(Nearby locations + shorter queue). When incorporating additional variables like time and potential datacenter disruptions (e.g., maintenance, power failures, or even submarine cable issues), the optimal solution evolves to min_response(Nearby *available* locations + shorter queue).</p> <p>However, forecasting all these conditions is challenging. Continuously querying every Gemini model globally to assess response times could paradoxically impede overall performance. This is precisely where Global Endpoints demonstrate their value! They intelligently determine which LLM model will deliver the quickest response, thereby accelerating your interactions.</p> <p>Back in March 2024, I whipped up a demo app that hit a global endpoint instead of a specific regional one, like us-central1 or europe-central2. Since I was working from my place in Warsaw, Poland, with an old router, I figured there might be some lag. But honestly, the huge performance difference between the global endpoint and my go-to europe-west1 was pretty wild-in a good way!</p> <p></p> <p>Based on my personal explorations and practical experience, employing Global Endpoints(GE) can significantly enhance the speed of your Gemini application. While GE are an excellent choice, they do have some limitations.</p> <ol> <li>Data Localization: If your app needs to keep data in a specific place (like for GDPR), GE might not be the right choice.</li> <li>LLM\u2019s Features Limitation: Certain features, such as RAG (Vector Search) built in specific locations (e.g., Europe or US-Central), may not be available for use.</li> </ol>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#022-using-gemini-lite-models","title":"022 Using Gemini-Lite Models","text":"<p>Upon the initial announcement of the Gemini Live API, I was quite enthusiastic, particularly regarding the integration of WebSockets, which I find to be remarkably efficient compared to standard HTTPS requests. Following exploration, I determined that a text-based chat proved to be the optimal choice for my needs, rather than audio or video conferencing.</p> <p>Although the Live API offers robust transcription options for both input and output (https://cloud.google.com/vertex-ai/generative-ai/docs/live-api#transcribe_audio), I found text-based interaction more effective(simple and fast enough) as it allowed me to review my queries before submission.</p> <p>These two considerations led me to consistently utilize the gemini-flash-lite models for straightforward chatbot applications.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#takeaway-03-cost-saving","title":"Takeaway 03: Cost Saving","text":""},{"location":"google-cloud-gemini-cookbook/lesson-05/#031-use-context-caching","title":"031 Use Context Caching","text":"<p>When leveraging Gemini for token usage tracking through observability, you might encounter a pleasant surprise: Gemini\u2019s Implicit Context Caching (ICC) and Explicit Context Caching (ECC) features. By default, ICC is active but can be disabled if necessary.</p> <p>As with any caching mechanism, the effectiveness is determined by the cache-hit to cache-miss ratio. With ICC, cost savings are not guaranteed. For instance, if you process 100\u2013200 distinct queries across various languages, a common token cache is not feasible, and Gemini cannot provide cost savings in such scenarios.</p> <p>In contrast to ICC, ECC offers a guaranteed cost reduction. While ECC is a powerful feature, its implementation is a design choice. Achieving cost-effectiveness with ECC, akin to reaching escape velocity, requires hitting a specific mathematical threshold. It\u2019s not magic, just pure mathematics!</p> <p>My recommendation is to consider using ECC when you have about 200+ queries and need a large context (dataset) in a short duration. For example, (1) you are building an Astro-Science Chatbot knowledgeable in a dozen physics, chemistry, and astrophysics books (2) You have to deal with really smart kids (I hope AI could handle those queries).</p> <p>Here is a quick recap of takeaway 031.</p> <p></p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#032-provision-throughput-pt","title":"032 Provision Throughput (PT)","text":"<p>This is Vertex AI only feature.</p> <p>Provisioned Throughput is a fixed-cost, fixed-term subscription available in several term-lengths that reserves throughput for supported generative AI models on Vertex AI. To reserve your throughput, you must specify the model and available locations in which the model runs.</p> <p>It is important to note that exceeding your Provisioned Throughput limit will not halt your requests. While this ensures uninterrupted service by preventing errors, it also means you cannot cap your Gemini costs if budget constraints are a concern.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#takeaway-04-context-awareness","title":"Takeaway 04: Context Awareness","text":"<p>Whether it\u2019s Gemini or some other LLMs, it\u2019s always the same rule. People are calling context the king but when I was learning data science, I heard a similar quote about Data / Information.</p> <p>Let me take a personal example here. Back in 2015, my colleagues had a simple classification challenge but the difficult part was the data distribution. Client has provided 1 TB of data positive data and 10 MB of negative data. (1,000,000 MB of positive data set and 10 MB is -tive dataset). The substantial disparity in data distribution made all our initial models predominantly classified queries as positive, achieving approximately 99.999% accuracy. However it was not the solution we needed.</p> <p>When I say context, it is the data relevancy. If your queries are not relevant to the context or theme you have set for the model, then you may be doing something fundamentally wrong. Imagine studying poetry to improve painting.</p> <p>So to keep your model responses relative to what users need, with gemini I have tested the following approaches</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#041-use-system-instructions","title":"041 Use System Instructions:","text":"<p>Define all the critical details that your model needs to remember. For example, \u201cYou are Bill Nye, the science guy. You are an American science communicator, television presenter, and former mechanical engineer. You are best known as the host of the science education television show Bill Nye the Science Guy and as a science educator in pop culture.\u201d (Copied from wikipedia)</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#042-use-grounding-with-google-search","title":"042 Use Grounding with Google Search:","text":"<p>To the scope limited, many times LLM models are not connected to search engines like Google (or DuckDuckGo or Yahoo). By enabling this, you can allow Gemini Model to browse the internet and get the latest information like date, climate and so on.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#043-use-rag","title":"043 Use RAG:","text":"<p>Similar to Grounding with Google Search, you may find your in a case where you want the model to automatically learn information about a certain project or certain dataset that is private to you or your team or organization. In such cases, using RAG has turned out to be an amazing investment.</p> <p>Using Vertex AI\u2019s RAG feature, all the provided data is converted into vectors and stored in a Vector database. When user queries, relevant data is identified from this Vector database and included as part of the overall context for the Model. As you may expect now this allows the model to get relevant answers.</p> <p>Here is a quick recap of takeaway 04.</p> <p></p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#takeaway-05-simplicity","title":"Takeaway 05: Simplicity","text":"<p>Simplicity stands as a crucial principle. Throughout my development and refinement of applications, I\u2019ve experimented with various LLM assisting tools. The Gemini CLI consistently proved most effective. Yet, even with this preference, it occasionally exhibited hallucinations, while other selections yielded even less favorable results. One time as an experiment, I allowed these changes to persist, meticulously reviewing each. This process finally led to a visually very appealing application with substantial code. During testing, as errors emerged, the model would rectify them. After several iterations, I realized I no longer genuinely enjoyed the application I had built. While aesthetically pleasing, I lacked the confidence to assume ownership for future feature additions or bug fixes. Gemini handled much of the work, but my engineering accountability kept me on edge.</p> <p></p> <p>Consider this: if a bug exists within 10 lines of code, the probability of quickly identifying it is 10%; however, in 500 lines of code, that probability drops to 0.2% (The layered approach in modules 03 and 04 simplified my code, resulting in faster debugging and error correction.)</p> <p>Simple designs are easier to understand, build, and maintain. As mentioned in Takeaway 01, a layered approach is helpful, but always prioritize simplicity in its execution. Ultimately, ensure your code is readable and simple for humans.</p>"},{"location":"google-cloud-gemini-cookbook/lesson-05/#conclusion","title":"Conclusion:","text":"<p>When building Gemini applications, a clear, layered, and straightforward design leads to robust, debuggable, and maintainable solutions, enabling powerful, efficient, and cost-effective Gemini-powered experiences.</p> <p>As this series concludes, remember that simplicity is key to great Gemini apps. These five takeaways are your secret ingredients for success. The next adventure awaits with the Google Agent Development Kit.</p> <p>Don\u2019t stop here! Our next post will explore the Google Agent Development Kit (ADK), built on the Google Gen AI SDK, to enhance your Gemini development journey. Lets go beyond the basics and build something outstanding in Gen AI.</p> <p>Now something for fun :)</p> <p></p>"},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/category/general/","title":"General","text":""}]}